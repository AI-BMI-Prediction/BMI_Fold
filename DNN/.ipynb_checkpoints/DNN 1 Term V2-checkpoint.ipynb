{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4661d8e",
   "metadata": {},
   "source": [
    "## 기본 베이지 DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdca589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeInGyu\\anaconda3\\envs\\dnn\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support as sk\n",
    "from sklearn.metrics import f1_score ## F1 Score 구하기\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "   \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f43b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.input_layer = nn.Linear(6, 128)\n",
    "        self.hidden_layer1 = nn.Linear(128, 256)\n",
    "        self.hidden_layer2 = nn.Linear(256, 128)\n",
    "        self.output_layer   = nn.Linear(128,3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out =  self.relu(self.input_layer(x))\n",
    "        out =  self.relu(self.hidden_layer1(out))\n",
    "        out =  self.relu(self.hidden_layer2(out))\n",
    "        out =  self.output_layer(out)\n",
    "        return out \n",
    "\n",
    "# device 설정 (cuda:0 혹은 cpu)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DNNModel() # Model 생성\n",
    "model.to(device)   # device 에 로드 (cpu or cuda)\n",
    "\n",
    "# 옵티마이저를 정의합니다. 옵티마이저에는 model.parameters()를 지정해야 합니다.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 손실함수(loss function)을 지정합니다. Multi-Class Classification 이기 때문에 CrossEntropy 손실을 지정하였습니다.\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ee7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Progress Bar 출력\n",
    "\n",
    "def model_train(model, data_loader, loss_fn, optimizer, device):\n",
    "    # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n",
    "    model.train()\n",
    "    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "    running_loss = 0\n",
    "    corr = 0\n",
    "\n",
    "    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n",
    "    prograss_bar = tqdm(data_loader)\n",
    "\n",
    "    # mini-batch 학습을 시작합니다.\n",
    "    for data, lbl in prograss_bar:\n",
    "#     for data, lbl in data_loader:\n",
    "        # image, label 데이터를 device에 올립니다.\n",
    "        data, lbl = data.to(device), lbl.to(device)\n",
    "        # 누적 Gradient를 초기화 합니다.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Propagation을 진행하여 결과를 얻습니다.\n",
    "        output = model(data)\n",
    "\n",
    "        # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n",
    "        loss = loss_fn(output, lbl)\n",
    "        # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n",
    "        loss.backward()\n",
    "\n",
    "        # 계산된 Gradient를 업데이트 합니다.\n",
    "        optimizer.step()\n",
    "\n",
    "        # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n",
    "        # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n",
    "        _, pred = output.max(dim=1)\n",
    "        # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n",
    "        # 합계는 corr 변수에 누적합니다.\n",
    "        corr += pred.eq(lbl).sum().item()\n",
    "        \n",
    "        # loss 값은 1개 배치의 평균 손실(loss) 입니다. data.size(0)은 배치사이즈(batch size) 입니다.\n",
    "        # loss 와 data.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "\n",
    "    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n",
    "    acc = corr / len(data_loader.dataset)\n",
    "    # 평균 손실(loss)과 정확도를 반환합니다.\n",
    "    # train_loss, train_acc\n",
    "    return running_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac3824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, data_loader, loss_fn, device):\n",
    "    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다. \n",
    "    # dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n",
    "    model.eval()\n",
    "    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n",
    "    with torch.no_grad():\n",
    "        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "        corr = 0\n",
    "        running_loss = 0\n",
    "\n",
    "        # 배치별 evaluation을 진행합니다.\n",
    "        for data, lbl in data_loader:\n",
    "            # device에 데이터를 올립니다.\n",
    "            data, lbl = data.to(device), lbl.to(device)\n",
    "\n",
    "            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n",
    "            output = model(data)\n",
    "\n",
    "            # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n",
    "            # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n",
    "            _, pred = output.max(dim=1)\n",
    "            \n",
    "\n",
    "            # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n",
    "            # 합계는 corr 변수에 누적합니다.\n",
    "            corr += torch.sum(pred.eq(lbl)).item()\n",
    "            \n",
    "            # loss 값은 1개 배치의 평균 손실(loss) 입니다. data.size(0)은 배치사이즈(batch size) 입니다.\n",
    "            # loss 와 data.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "            # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "            running_loss += loss_fn(output, lbl).item() * data.size(0)\n",
    "\n",
    "        # validation 정확도를 계산합니다.\n",
    "        # 누적한 정답숫자를 전체 데이터셋의 숫자로 나누어 최종 accuracy를 산출합니다.\n",
    "        acc = corr / len(data_loader.dataset)\n",
    "\n",
    "        # 결과를 반환합니다.\n",
    "        # val_loss, val_acc\n",
    "        return running_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc43103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(model, data_loader, loss_fn, device):\n",
    "    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다. \n",
    "    # dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n",
    "    model.eval()\n",
    "    pred_list=[]\n",
    "    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n",
    "    with torch.no_grad():\n",
    "        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "        corr = 0\n",
    "        running_loss = 0\n",
    "\n",
    "        # 배치별 evaluation을 진행합니다.\n",
    "        for data, lbl in data_loader:\n",
    "            # device에 데이터를 올립니다.\n",
    "            data, lbl = data.to(device), lbl.to(device)\n",
    "\n",
    "            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n",
    "            output = model(data)\n",
    "            \n",
    "            \n",
    "            # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n",
    "            # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n",
    "            _, pred = output.max(dim=1)\n",
    "            pred_array = pred.tolist()\n",
    "            pred_list.append(pred_array) # confusion matrix를 위해 pred 리턴 값\n",
    "            # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n",
    "            # 합계는 corr 변수에 누적합니다.\n",
    "            corr += torch.sum(pred.eq(lbl)).item()\n",
    "            \n",
    "            # loss 값은 1개 배치의 평균 손실(loss) 입니다. data.size(0)은 배치사이즈(batch size) 입니다.\n",
    "            # loss 와 data.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "            # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "            running_loss += loss_fn(output, lbl).item() * data.size(0)\n",
    "\n",
    "        # validation 정확도를 계산합니다.\n",
    "        # 누적한 정답숫자를 전체 데이터셋의 숫자로 나누어 최종 accuracy를 산출합니다.\n",
    "        acc = corr / len(data_loader.dataset)\n",
    "\n",
    "        # 결과를 반환합니다.\n",
    "        # val_loss, val_acc\n",
    "        return running_loss / len(data_loader.dataset), acc, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71d4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b821ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 144.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19121, acc: 0.92129, val_loss: 0.40550, val_accuracy: 0.87936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 202.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.24070, acc: 0.90691, val_loss: 0.21423, val_accuracy: 0.91568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 208.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.22315, acc: 0.91231, val_loss: 0.18734, val_accuracy: 0.92653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 168.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.21444, acc: 0.91039, val_loss: 0.21911, val_accuracy: 0.91275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 196.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.21543, acc: 0.91530, val_loss: 0.21603, val_accuracy: 0.91401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 200.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.21509, acc: 0.91132, val_loss: 0.20099, val_accuracy: 0.92528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 208.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.21437, acc: 0.91377, val_loss: 0.19683, val_accuracy: 0.91964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 163.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20949, acc: 0.91236, val_loss: 0.19930, val_accuracy: 0.92194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 190.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20313, acc: 0.91830, val_loss: 0.20294, val_accuracy: 0.92006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 200.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20982, acc: 0.91663, val_loss: 0.20943, val_accuracy: 0.91254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 125.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20381, acc: 0.91362, val_loss: 0.53336, val_accuracy: 0.87341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 190.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.24101, acc: 0.90699, val_loss: 0.21456, val_accuracy: 0.91221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 203.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.21509, acc: 0.91142, val_loss: 0.20608, val_accuracy: 0.91306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 204.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.22355, acc: 0.90468, val_loss: 0.19531, val_accuracy: 0.92324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 212.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.21895, acc: 0.90815, val_loss: 0.19430, val_accuracy: 0.91750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 162.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.21164, acc: 0.91216, val_loss: 0.22164, val_accuracy: 0.91262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 209.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20759, acc: 0.91414, val_loss: 0.20453, val_accuracy: 0.91919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 217.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20629, acc: 0.91157, val_loss: 0.19108, val_accuracy: 0.91877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 210.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20754, acc: 0.91352, val_loss: 0.19096, val_accuracy: 0.92216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 168.61it/s]\n",
      "C:\\Users\\LeeInGyu\\anaconda3\\envs\\dnn\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20511, acc: 0.91322, val_loss: 0.20136, val_accuracy: 0.91283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20422, acc: 0.91478, val_loss: 0.18298, val_accuracy: 0.92502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 209.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20413, acc: 0.91588, val_loss: 0.20418, val_accuracy: 0.91230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 212.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.21073, acc: 0.91167, val_loss: 0.21811, val_accuracy: 0.91338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 193.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20479, acc: 0.91586, val_loss: 0.19587, val_accuracy: 0.92092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 160.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20128, acc: 0.91799, val_loss: 0.18666, val_accuracy: 0.92522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 245.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20378, acc: 0.91617, val_loss: 0.19011, val_accuracy: 0.92155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 252.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20160, acc: 0.91737, val_loss: 0.18626, val_accuracy: 0.92586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 252.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20338, acc: 0.91627, val_loss: 0.19031, val_accuracy: 0.92737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 252.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19749, acc: 0.92055, val_loss: 0.18885, val_accuracy: 0.92759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 164.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19697, acc: 0.91897, val_loss: 0.17447, val_accuracy: 0.92414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 129.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19656, acc: 0.91674, val_loss: 0.20265, val_accuracy: 0.92141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 214.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19838, acc: 0.91941, val_loss: 0.17729, val_accuracy: 0.92907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 196.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20037, acc: 0.91250, val_loss: 0.18551, val_accuracy: 0.92338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 197.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20315, acc: 0.91576, val_loss: 0.18233, val_accuracy: 0.92513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 211.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19848, acc: 0.91747, val_loss: 0.18632, val_accuracy: 0.92404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 205.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20735, acc: 0.91134, val_loss: 0.16833, val_accuracy: 0.93039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 150.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20048, acc: 0.91749, val_loss: 0.17638, val_accuracy: 0.93214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 201.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19782, acc: 0.91800, val_loss: 0.19719, val_accuracy: 0.91813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 199.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19847, acc: 0.91574, val_loss: 0.17105, val_accuracy: 0.93146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 217.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19715, acc: 0.91584, val_loss: 0.18677, val_accuracy: 0.92643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 81/81 [00:00<00:00, 161.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19729, acc: 0.91513, val_loss: 0.19070, val_accuracy: 0.92034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 81/81 [00:00<00:00, 206.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20725, acc: 0.91201, val_loss: 0.19191, val_accuracy: 0.92321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 81/81 [00:00<00:00, 198.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20025, acc: 0.91617, val_loss: 0.19616, val_accuracy: 0.92054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 81/81 [00:00<00:00, 201.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20033, acc: 0.91765, val_loss: 0.19458, val_accuracy: 0.91609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 81/81 [00:00<00:00, 196.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.20527, acc: 0.91224, val_loss: 0.16319, val_accuracy: 0.93323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 81/81 [00:00<00:00, 128.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19610, acc: 0.91884, val_loss: 0.17809, val_accuracy: 0.92522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 81/81 [00:00<00:00, 187.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19901, acc: 0.91790, val_loss: 0.16748, val_accuracy: 0.92945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 81/81 [00:00<00:00, 228.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19077, acc: 0.91965, val_loss: 0.17382, val_accuracy: 0.93056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 81/81 [00:00<00:00, 238.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19244, acc: 0.91988, val_loss: 0.16433, val_accuracy: 0.93167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 81/81 [00:00<00:00, 231.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19533, acc: 0.91471, val_loss: 0.16434, val_accuracy: 0.93056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 155.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19186, acc: 0.91826, val_loss: 0.16666, val_accuracy: 0.93395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 212.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.18848, acc: 0.92234, val_loss: 0.17118, val_accuracy: 0.92536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 204.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.18711, acc: 0.92573, val_loss: 0.18145, val_accuracy: 0.92423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 211.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19075, acc: 0.91907, val_loss: 0.17597, val_accuracy: 0.92762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 205.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19260, acc: 0.91955, val_loss: 0.15881, val_accuracy: 0.93237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 222.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.18723, acc: 0.92284, val_loss: 0.15052, val_accuracy: 0.93667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 138.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.18570, acc: 0.92136, val_loss: 0.18623, val_accuracy: 0.92649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 201.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, loss: 0.19108, acc: 0.92088, val_loss: 0.16960, val_accuracy: 0.93350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 211.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('./1term_data'):\n",
    "    \n",
    "    filename=file.rstrip('.xlsx')\n",
    "    #Dataframe 읽고 X y 나누기\n",
    "    df=pd.read_excel('./1term_data/'+file)\n",
    "    X=df.iloc[:,[1,3,4,5,6,7]]\n",
    "    y=df.iloc[:,-1]\n",
    "    \n",
    "    #Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaler = scaler.fit_transform(X)\n",
    "    \n",
    "    #SMOTE 적용\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train_over,y_train_over = smote.fit_resample(X_scaler,y)\n",
    "#     print('SMOTE 적용 전 레이블 값 분포: \\n', pd.Series(y).value_counts())\n",
    "#     print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())\n",
    "    \n",
    "    #kFold\n",
    "    skf=StratifiedKFold(n_splits=10,shuffle=True)\n",
    "    \n",
    "    num_epochs = 300\n",
    "    i=0    \n",
    "    \n",
    "    #결과 넣을 배열\n",
    "    most_acc=[]\n",
    "    empty=pd.DataFrame()\n",
    "    CMResult=[[[0 for k in range(3)]for j in range(3)] for i in range(10)]\n",
    "    Result=[[0 for j in range(4)] for i in range(10)]\n",
    "    loss_list=[[0 for j in range(num_epochs)] for i in range(10)]\n",
    "    acc_list=[[0 for j in range(num_epochs)] for i in range(10)]\n",
    "    AverageCM=[[0 for i in range(3)] for j in range(3)]\n",
    "    \n",
    "    for train_index, test_index in skf.split(X_train_over,y_train_over):\n",
    "        X_train, X_test = X_train_over[train_index], X_train_over[test_index]\n",
    "        y_train, y_test = y_train_over[train_index], y_train_over[test_index]\n",
    "\n",
    "        X_train = torch.FloatTensor(X_train)\n",
    "        X_test = torch.FloatTensor(X_test)\n",
    "        y_train = torch.LongTensor(y_train.to_numpy())\n",
    "        y_test = torch.LongTensor(y_test.to_numpy())\n",
    "\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        test_dataset=TensorDataset(X_test, y_test)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=500,shuffle=False)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=200,shuffle=False)\n",
    "\n",
    "        # 최대 Epoch을 지정합니다.\n",
    "        min_loss = 9999999999999\n",
    "        # Epoch 별 훈련 및 검증을 수행합니다.\n",
    "        temp_loss=[]\n",
    "        temp_acc=[]\n",
    "        for epoch in range(num_epochs):\n",
    "            # Model Training\n",
    "            # 훈련 손실과 정확도를 반환 받습니다.\n",
    "            train_loss, train_acc = model_train(model, train_dataloader, loss_fn, optimizer, device)\n",
    "\n",
    "            # 검증 손실과 검증 정확도를 반환 받습니다.\n",
    "            val_loss, val_acc = model_evaluate(model, test_dataloader, loss_fn, device)   \n",
    "\n",
    "            # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
    "            if val_loss < min_loss:\n",
    "#                     print(f'[INFO] val_acc has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n",
    "                    min_loss = val_loss\n",
    "                    torch.save(model.state_dict(), 'DNNModel.pth')\n",
    "\n",
    "            # Epoch 별 결과를 출력합니다.\n",
    "            if(epoch%50==0):\n",
    "                print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')\n",
    "            temp_loss.append(train_loss)\n",
    "            temp_acc.append(train_acc)\n",
    "            \n",
    "        ## 저장한 가중치 로드 후 검증 성능 측정\n",
    "        \n",
    "        loss_list[i]=temp_loss\n",
    "        acc_list[i]=temp_acc\n",
    "              \n",
    "        # 모델에 저장한 가중치를 로드합니다.\n",
    "        model.load_state_dict(torch.load('DNNModel.pth'))\n",
    "\n",
    "        # 최종 검증 손실(validation loss)와 검증 정확도(validation accuracy)를 산출합니다.\n",
    "#         print(\"{}번째 교차검증\".format(i))\n",
    "        final_loss, final_acc, pred_list = model_test(model, test_dataloader, loss_fn, device)\n",
    "#         print(f'evaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}')\n",
    "        \n",
    "        pred_list=flatten_list(pred_list)\n",
    "        pred_list=np.array(pred_list)\n",
    "        pred_list=pred_list.astype(np.int64)\n",
    "        y_test=y_test.numpy()\n",
    "        y_test_list=y_test.tolist()\n",
    "#       --------------------------------------------------------------------------------\n",
    "        #여기까지 pred_list : prediction, y_test : 실제값                          \n",
    "        \n",
    "        df_pred=(pd.DataFrame(pred_list)).value_counts()\n",
    "        df_pred.columns=['Prediction']\n",
    "        df_real=(pd.DataFrame(y_test)).value_counts()\n",
    "        df_real.columns=['Real']\n",
    "        df_values=pd.concat([df_pred,df_real],axis=1)\n",
    "        \n",
    "        path='./Result/ValueCount/'+filename\n",
    "        isExist = os.path.exists(path)\n",
    "        if not isExist:\n",
    "            os.makedirs(path)     \n",
    "        df_values.to_csv('./Result/ValueCount/'+filename+'/'+filename+str(i)+'value_count.csv')\n",
    "        \n",
    "        accuracy=accuracy_score(y_test, pred_list)\n",
    "#         print(filename + \"[{}]Accuracy : {}\".format(i,accuracy))   \n",
    "        \n",
    "        #f1score\n",
    "        f1 = f1_score(y_test,pred_list, average='weighted')\n",
    "#         print(filename + \"[{}]F1score : {}\".format(i,f1))\n",
    "        \n",
    "        #precision/recall\n",
    "        p_rlist=sk(y_test,pred_list,average='weighted')\n",
    "#         print(filename + \"[{}]Precision : {}\".format(i,p_rlist[0]))\n",
    "#         print(filename + \"[{}]Recall : {}\".format(i,p_rlist[1]))\n",
    "        \n",
    "                                  \n",
    "        #결과 배열에 넣기\n",
    "        Result[i][0]=accuracy\n",
    "        Result[i][1]=f1\n",
    "        Result[i][2]=p_rlist[0]\n",
    "        Result[i][3]=p_rlist[1]\n",
    "        \n",
    "        cm=confusion_matrix(y_test, pred_list,normalize=\"true\")\n",
    "        CMResult[i]=cm\n",
    "        \n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[0,1,2])\n",
    "        disp.plot()\n",
    "        path='./ConfusionMatrix/'+filename\n",
    "        isExist = os.path.exists(path)\n",
    "        if not isExist:\n",
    "            os.makedirs(path)     \n",
    "        plt.savefig(\"./ConfusionMatrix/\"+filename+\"/\"+filename+\"_\"+str(i)+\"_CM.png\")\n",
    "#         plt.show()\n",
    "        i=i+1\n",
    "        \n",
    "    df_result=pd.DataFrame(Result,columns=['Accuracy','F1score','Precision','Recall'])\n",
    "    df_result_mean=df_result.mean()\n",
    "    df_result2=pd.concat((df_result,df_result_mean),axis=1,ignore_index=True,)\n",
    "    df_result2.to_csv('./Result/'+filename+'_Result.csv')    \n",
    "    \n",
    "    \n",
    "    AverageCM=[[0 for i in range(3)] for j in range(3)]\n",
    "    for i in range(10):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                AverageCM[j][k]=AverageCM[j][k]+CMResult[i][j][k]\n",
    "    \n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            AverageCM[j][k]=AverageCM[j][k]/10\n",
    "    \n",
    "    AverageCM=np.array(AverageCM)           \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=AverageCM,display_labels=[0,1,2])\n",
    "    disp.plot()\n",
    "    plt.savefig(\"./ConfusionMatrix/AverageConfusionMatrix/\"+filename+\".png\")\n",
    "#     plt.show()\n",
    "    \n",
    "    df_loss=pd.DataFrame(loss_list)\n",
    "    df_loss.to_csv('./Loss/'+filename+'_loss.csv')\n",
    "    \n",
    "    df_acc=pd.DataFrame(acc_list)\n",
    "    df_acc.to_csv('./Accuracy/'+filename+'_accuracy.csv')\n",
    "    \n",
    "    del Result\n",
    "    del CMResult\n",
    "    del loss_list\n",
    "    del acc_list\n",
    "    del AverageCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5a0505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682bcfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dnn",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
